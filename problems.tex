%Twitter api, out of requests
\subsection{Twitter API requests}
The initial plan was to use the open Twitter API at the server side to retrieve search results, user info, trending topics etc. The Twitter API consist of several APIs, one for each type of Twitter data each limited to a 150 requests an hour. We discovered quite early in the development process that this number was far too low to be usable in practice. 

A first try at a solution was heavy use of caching of search results (tweets, users and trending topics). The use of caching was also required for user ranking, as we would need to have our own database of users to calculate the ranks. We soon found that the caching solution was not good enough because the ranking algorithm requires the storage of information about which users follow a user, and which users a user follows. Each search thus required up to 41 requests to the user API, almost a third of the available requests, which amounts to about three searches an hour.

Finally, we decided to move all user and search requests client side. As a result, the amount of information the server can cache is only limited to the amount of users that use the system. It should be noted that the problem has only been moved client side and as a result, users are now only able to do about four searches an hour. As our database grows however, the restriction should be somewhat alleviated.

%Server probl
\subsection{Server Problems}

%fake data probl
\subsection{SQL/JSON injection}
Due to the Twitter API request limit and the resulting AJAX client workaround we have in essence opened our application to fraudulent input from the client. Since we have no control over the client, and due to the fact that the users have full control, they will be able to construct fake, but valid JSON data to send to our controllers. Basically this means that they will be able to create fake users, user data (such as descriptions), and fake the tables lising followers and following. They will also be able to dictate the content to show in the tweets we display.

There is no way that we can ensure that such fraudulent data does not make its way into our database outside of conducting all the queries server side, which as previously explained proved to be a bad solution due to the request limit. While it is possible to insert correctly formatted data, it is not possible to inject SQL statements due to our use of named parameters. In addition to this the fraudulent data problem is somewhat alleviated by our revisiting policy which ensures that this fraudulent data will be exchanged for new data after a period of 4 weeks.
