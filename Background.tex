%teoridel
In this section we will present background information relevant to our project. We will start by introducing ranking in relation to search engines. After this we will take a closer look at the Google PageRank algorithm which is the foundation of the FeedJam ranking algorithm.  Following the section on the PageRank algorithm we will shortly introduce Twitter, the social media that is the domain of our research. The background section will end with a presentation of work related to our project.

\subsection{Ranking} 
In defining the goals for this project we chose to focus on two parts of the web information retrieval process, ranking and presentation of search results. Ranking is the hardest and most important function of a search engine \cite[p.469]{Baeza-Yates2011}. One of the key challenges in ranking, according to \citet{Baeza-Yates2011}, is to identify quality content on the web. Evidence of quality can be indicated by several signals such as domain names [...], text content, and various counts (such as the number of word occurrences), links (like PageRank), and Web page access patterns as monitored by the search engine” \citep[p.468]{Baeza-Yates2011}. \citet{Baeza-Yates2011} goes on to describe different types of signals that can be used to improve ranking of web results. These will be briefly described here. Content signals refers to the content of the document, mainly text. The signal in the content type refers to things such as word counts, vector space model-based scores and so forth. Structural signals, according to \citet{Baeza-Yates2011}, includes signals such as the links on a page, the text in anchor elements, and in and out-links to a page.  The last signal type describes is the web usage signals. User clicks is one often used signal where the relevance of a result is affected by the number of clicks it receives. Other signals mentioned are geographical location, language, technological context and temporal context (that is web usage over time gathered through cookies or user profiles)\citep{Baeza-Yates2011}.

Content signals will be used in FeedJam's TweetRank. We will explain in more detail about how we use hashtags, mentions and retweets to create a score in section~\ref{sec:application}.

Link-based ranking is based on using structural signals (i.e. counting the number of outgoing and incoming links on a page) to rank a page or document. One ranking algorithm based on this  principle is the Google PageRank algorithm \citep{Page1999}. We will use this to create a UserRank for Twitter users. 

\subsubsection{Page Rank}
%something about that pagerank comes from the idea of citations counting in journals. If a journal is cited in many articles it is most likely an important article. PageRank takes this idea one step forther. 
The goal of the PageRank ranking algorithm is stated as follows: “This ranking called PageRank helps search engines and users quickly make sense of the vast heterogeneity of the World Wide Web” \citep[p. 1]{Page1999}. It derives from citation counting which is a way tell the importance of an article. An article that is cited by many other articles is most likely an important one. 

The PageRank algorithm exploits the structure of the web in the calculation of the rank. The World Wide Web can thus be viewed as a graph with directed edges between nodes. The edges are either links pointing to the page - we call them back-links. Or they are links pointing to another page - called outgoing-links or forward-links. Looking at the structure of the web and trying to create a ranking of web pages, \citet{Page1999} took the idea of citations counting one step further. In addition to the number of web pages that point to a page, it also looks at the actual pages that link to it. \citet{Page1999} noted that giving high ranks just by looking at the number of back-links (incoming links) is problematic because a site might get many back-links from various web pages that are not very important. They provide a solution to this by proposing that not only the number of back-links, but also the rank of the web pages for these back-links can be used when ranking a web page. Given this solution, as shown by \citet{Page1999}, a page receives a high page rank if the sum of the page ranks of the back-links is high.

The PageRank algorithm simulates a user navigating through the web randomly. The user is currently at page \emph{a}. From here she randomly clicks on one of the links on page \emph{a} to get to the next page. The process is repeated. Using the pattern created by many numbers of clicks by the user, it is possible to compute the probability of which the user has visited each page. There are some restrictions to the computation. The web has pages without outgoing links and self-links where the user is not able to move on. Another aspect we have to consider is the probability that the user moves to another page not using the links on the current page. Following we calculate PageRank:
Let \emph{L(p)} be the number of outgoing links of page \emph{p} and let \emph{p1 ... pn} be the pages that point to page a. q is the probability that the user jumps to another page and \emph{1-q} is the probability that she follows the link.  Then the PageRank of page a is given by the probability \emph{PR(a)} of finding the user in that page

\begin{displaymath}
PR(a) = \frac{q}{T} + (1 − q) \sum_{i=1}^{n} \frac{PR(p_i)}{L(p_i)}
\end{displaymath}

where:\newline
\emph{T}: total number of pages on the Web graph\newline
\emph{q}: parameter set by the system (typical value is 0.15)

When computing the algorithm we have to consider the problem of pages with no outgoing links. \citet{Baeza-Yates2011} propose two solutions. One is to put \emph{q = 1} for these pages, the other is to leave them out, and compute their rank at the end based on their parents rank. 


\subsection{User Interface}
In addition to applying the PageRank algorithm we aim to create a novel interface for displaying tweets.

\subsubsection{Interaction design principles and user-centered design}
Within the field of interaction design we have several different design guidelines and principles for creating usable artefacts. \citet{Sharp2007} name visibiity, feedback, constraints, consistency and affordance as the essential design principles.

\begin{description}
  \item[Visibility] important controls should be visible
  \item[Feedback] there should be some effect after performing an action
  \item[Constraints] impossible options should be hidden/clearly disabled
  \item[Consistency] similar operations should use similar elements and function similarily
  \item[Affordance] one can use affordances (natural cues, e.g that a button can be clicked) where applicable in a user interface
\end{description}

\subsubsection{Classic search engine result pages}
\citet[p.480]{Baeza-Yates2011} argues that existing search engines are heavily influenced by what they call a extreme simplicity rule. Basically this rule states that search engine user experience must be simplistic enough in nature that users understand it without any previous knowledge, or else they will simply switch to another search engine. This has lead to a very prominent interface paradigm where all the most prominent search engines use the classic search engine result page (SERP) \citep{Baeza-Yates2011}. 

As search engines have started to search several different content types the need to display several different media types in one unified result page have also emerged. This has resulted in two innovations: the “onebox” \citep{Baeza-Yates2011}, which displays specific information from one knowledge domain (e.g weather reports) and universal search results where one combines several different searches into one search result page.

\subsection{Twitter}
\label{Twitter}
%litt om hvordan twitter kan være vanskelig å få oversikt over en strøm. finn statistikk om megden tweets i døgnet.
%vi kan tilby noe mer enn twitter search enginen gir. Vi tilbyr en mer oversiktlig tjeneste. 
%se om det finnes noe som sier noe om hvordna brukere bruekr twitter. 
When deciding what information retrieval (IR) techniques we could apply to Twitter we found that when searching for tweets it not easy to see which are important and which are not. If you search for a certain topic on Twitter you get a feed of all recent tweets that match the search query. It can be everything from a users personal diary, a conversation between users, some other form of information sharing or spam. Considering this, we wanted to use information retrieval (IR) techniques to make it easier to get a quick overview to see what tweets are important. 

%Find stats from twitter, stats om twitter brukere
Twitter is a microblogging service with over 130 million daily visitors \citep{WolframAlpha}, available for more than 20 languages \citep{Twitter2012}. Users posts messages, called tweets, about what they find interesting. These tweets are in turn shared with the world and in turn potentially read by other users. As Twitter has become popular it has received a broad user group. The difference between Twitter and other social networks is the way that it defines the relationships in the network. On Twitter users follows other users and is followed by other users. The difference compared to other major social networks is that the relationship doesn't have to be reciprocal. Being a follower means you receive all the tweets of the users you follow. \citep{Kwak2010} finds that 77.9\% of the followers relationships on Twitter are non-reciprocal. This is one of the features we will take advantage of in order to rank tweets. 

%\citep{boka kap11} Noe om distribusjonen av sider og linker på web i kap 11. .. noe om zipf lov. Pareto distribution similar to the power law. Many small documents Det samme gjelder for Twitter?

%Its hard to use any tradistional ranking methods on texsts as short as tweets. There are not many words to make word ranking, and the tweets aren't devided in sections which could have been wighted differently. But ee use the few textual features tweets has hashtags, mentions. 

Twitter also has other features that can be used in ranking. Important words in the text of a tweet can be marked with hashtags ("\#"). Tweets can be retweeted, a mechanism that facilitates spreading of tweets. \citep{Kwak2010} finds that a retweeted tweet reaches an average of 1000 users no matter what the number of followers of the  the original tweet's author is.

%make an argument that we cna use page rank on twitter users because they are linked together in a similar way that web pages are. Followers and following can be comared to in-and out-links on web pages. There are big and small users and the distributution of them  is the same(chech this from the statistics). A difference may be that users of Twitter might not navigate the Twitter users in the same way they fo the web. Maybe its more common to brows for tweets than users (find out how information seekers use twitter to get information).  Maybe the users follows the persons because they know they talk about somthing interesting. Btu maybe still you won't brows users following the users following. Or will you? It may be that the interesting person follows somone that you also want to follow. 

%Dette var noe jeg fant i en artikkel. OG det er ikke så vanskelig å implementer noe som sier om en bruker er venn, deler eller søker. Kanskje vi skal gjøre det?
Users use Twitter in different ways. \citet{Akshay2007} finds three main user categories: Information source, Friend and Information Seeker. Information sources are users that updates their status in regular intervals and has many followers. The number of followers is due to the value of the information in the tweets. The Information Seeker is a user who rarely post tweets, but follows other users on a regular basis. A Friend is a user with many reciprocal relationships. We may use these user categories in the UserRank.

FeedJam use the Twitter REST API to retrieve tweets and user information. More on how it is used and integrated in the application can be found in section \ref{viewControllerInteraction} and section \ref{interactionControllerModel}. 

\subsection{Related Work}
{\bf trst.me} \newline
trst.me \citet{Infochimps2012b} is tool for measuring a Twitter user's reputation. The measure is two dimensional and consists of the \emph{ Trstrank} and the \emph{Trstquitient}. The Trstrank is a implementation of Google's PageRank \citep{Infochimps2012a}, the same rank that FeedJam uses for its UserRank. The Trstrank gives a score between 0 and 10 which gives many users the same rank. To differentiate between the users trst.me uses the Trstquotient. It is "an integer between 0 and 100 that quantifies the relationship between a user's Trstrank and their followers count" \citep{Infochimps2012}. The quotient is used to separate spammers from quality users. 

trst.me compared to FeedJam is just a service for finding a Twitter user's trustworthiness. It allows users to enter the screen name of a Twitter user and returns their rank along with other related metrics.

